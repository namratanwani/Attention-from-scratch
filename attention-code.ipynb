{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Mechanism with custom input embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the word embeddings of only 3 tokens with their positions in input\n",
    "inp_emb1, pos1 = np.array([1,2,3,4]), 1\n",
    "inp_emb2, pos2 = np.array([4,5,2,3]), 2\n",
    "inp_emb3, pos3 = np.array([6,1,2,2]), 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In \"Attention is all you ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dimension for model is 4, for simplicity.\n",
    "dim_model = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$PE(pos_{2i}) = \\sin\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$PE(pos_{2i+1}) = \\cos\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformed word embedding: $$y_1 \\cdot \\sqrt{d_{\\text{model}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_model = 4\n",
    "def positional_encoding(inp_emb, pos):\n",
    "    \"\"\"\n",
    "    This function outputs the positional encoding of the inputs.\n",
    "    It first calculates the positional vector for each input using\n",
    "    sin and cos functions. Then, adds the positional vector to a\n",
    "    transformed word embedding.\n",
    "    The transformed word embedding retains the word embedding info\n",
    "    without being minimised by position information.\n",
    "    \"\"\"\n",
    "    pos_enc = [0]*dim_model\n",
    "\n",
    "    for i in range(0, dim_model-1, 2):\n",
    "        term = pos/(10000**((2*i)/dim_model))\n",
    "        pos_enc[i] = np.sin(term)\n",
    "        pos_enc[i+1] = np.cos(term)\n",
    "\n",
    "        transformed_word_emb = inp_emb*np.sqrt(dim_model)\n",
    "        pos_enc[i] = pos_enc[i] + transformed_word_emb[i]\n",
    "        pos_enc[i+1] = pos_enc[i+1] + transformed_word_emb[i+1]\n",
    "\n",
    "    \n",
    "    return pos_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_enc1 = positional_encoding(inp_emb1, pos1)\n",
    "pos_enc2 = positional_encoding(inp_emb2, pos2)\n",
    "pos_enc3 = positional_encoding(inp_emb3, pos3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.8414709848078967, 4.54030230586814, 6.000099999999834, 8.999999995]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_enc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.909297426825681, 9.583853163452858, 4.000199999998666, 6.99999998]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_enc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.141120008059866, 1.0100075033995546, 4.0002999999955, 4.999999955000001]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_enc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_input = np.array([pos_enc1, pos_enc2, pos_enc3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.84147098,  4.54030231,  6.0001    ,  8.99999999],\n",
       "       [ 8.90929743,  9.58385316,  4.0002    ,  6.99999998],\n",
       "       [12.14112001,  1.0100075 ,  4.0003    ,  4.99999996]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside attention mechanism, each word vector has 3 representations: A query vector (Q), A key vector (K), and a value vector (V). Here,\n",
    "\n",
    "Q = attention_input x W_Q\n",
    "\n",
    "K = attention_input x W_K\n",
    "\n",
    "V = attention_input x W_V\n",
    "\n",
    "Q, K, and V are obtained from matrix multiplication of wight matricex and input matrix. Here, W_Q, W_K, W_V  are the weights for each vector learnt and updated during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, We use the initialsed values of these weight vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for future matrix multiplication the number of columns in first\n",
    "#  matrix should be equal to the number of rows of the second matrix.\n",
    "dim_model = 4\n",
    "np.random.seed(12)\n",
    "def initialise_weights(dim,n):\n",
    "    W_Q = np.random.randint(n, size = (dim, dim))\n",
    "    W_K= np.random.randint(n, size = (dim, dim))\n",
    "    W_V = np.random.randint(n, size = (dim, dim))\n",
    "    return W_Q, W_K, W_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Q, W_K, W_V = initialise_weights(dim_model,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 1, 2],\n",
       "       [3, 3, 4, 0],\n",
       "       [1, 4, 1, 2],\n",
       "       [3, 2, 0, 0]])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 2, 1, 3],\n",
       "       [4, 3, 1, 0],\n",
       "       [2, 2, 0, 4],\n",
       "       [3, 1, 0, 0]])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 1, 3],\n",
       "       [0, 1, 1, 0],\n",
       "       [4, 0, 4, 1],\n",
       "       [3, 4, 3, 3]])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.matmul(attention_input, W_Q)\n",
    "K = np.matmul(attention_input, W_K)\n",
    "V = np.matmul(attention_input, W_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[55.14541986, 64.14571986, 27.00278021, 17.68314197],\n",
       "       [80.47965171, 85.48025173, 51.24491008, 25.81899485],\n",
       "       [58.4536824 , 65.45458244, 20.18145002, 32.28284002]])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 68.52729315,  40.30404888,   7.38177329,  32.52481295],\n",
       "       [102.9730023 ,  61.57055432,  18.49315059,  42.72869228],\n",
       "       [ 75.60510991,  40.31286248,  13.15112751,  52.42456002]])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[59.52481294, 49.06471524, 58.38217328, 41.52451294],\n",
       "       [63.72869222, 64.31174536, 55.49395053, 51.72809222],\n",
       "       [67.42455989, 57.43336735, 44.15232738, 55.42365989]])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right) V$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(Q,K,V, dim):\n",
    "    Q_againt_Kvalues = np.matmul(Q, K.T) / np.sqrt(dim)\n",
    "    softmax_score = softmax(Q_againt_Kvalues)\n",
    "    final_attention = np.matmul(softmax_score, V)\n",
    "    return final_attention\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [63.72869222, 64.31174536, 55.49395053, 51.72809222],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here, dim_k = dim_model\n",
    "attention(Q,K,V, dim_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention mechanism using Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The big cat sat on the mat.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'big', 'cat', 'sat', 'on', 'the', 'mat']"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"The big cat sat on the mat\"\n",
    "data = sentence.lower().split()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using CBOW \n",
    "model = Word2Vec([data], min_count=1, vector_size=224, window=2)\n",
    "\n",
    "embedding_dict = {}\n",
    "for word in data:\n",
    "    embedding_dict[word] = model.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings = np.array([\n",
    "    embedding_dict[word] for word in data\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 224)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_model = 224\n",
    "# pe = []*input_embeddings.shape[0]\n",
    "pe = [positional_encoding(input_embeddings[i], i+1) for i in range(input_embeddings.shape[0])]\n",
    "pe = np.array(pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 224)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to implement multi-head attention - with 4 heads (or 4 iterations in our case) and head dimension as 56."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Q, W_K, W_V = initialise_weights(56, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 56)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_inputs = []*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 224)"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_head = 56\n",
    "i = 0\n",
    "inputs_for_heads = [[]]*4\n",
    "for n in range(0,224,dim_head):\n",
    "    head_input = np.array([input_embed[n:n+56] for input_embed in input_embeddings])\n",
    "    # break\n",
    "    inputs_for_heads[i] = head_input\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 7, 56)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(inputs_for_heads).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = [[]] * 4\n",
    "K = [[]] * 4\n",
    "V = [[]] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_head = 56\n",
    "attention_outputs_from_heads = [[]]*4\n",
    "i = 0\n",
    "for head_input in inputs_for_heads:\n",
    "    Q = np.matmul(head_input, W_Q)\n",
    "    K = np.matmul(head_input, W_K)\n",
    "    V = np.matmul(head_input, W_V)\n",
    "\n",
    "    head_attention_output = attention(Q,K,V, dim_head)\n",
    "    attention_outputs_from_heads[i] = head_attention_output\n",
    "    i += 1\n",
    "attention_outputs_from_heads = np.array(attention_outputs_from_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 7, 56)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_outputs_from_heads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_attention = np.hstack(attention_outputs_from_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 224)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1839be193d0>"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAABSCAYAAABE4i1VAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfVklEQVR4nO3df5RVdf3v8dcZYAZEZnBAmJlERM3fQIUycUsr5Qrk1/xBqUSJRmY1mEqa0QrRbjdc8K1cmUtb36Xi/ZamfK/ajcouoqJ9HdAvXJZpORe4IBAMJjYMP+TXzL5/+OXUsF8f+BwPc85h5vlYi7XgfT6f/fm5P3ufzdl7Z5IkSQQAAAAAAACUqLJiVwAAAAAAAAA4GC5gAQAAAAAAoKRxAQsAAAAAAAAljQtYAAAAAAAAKGlcwAIAAAAAAEBJ4wIWAAAAAAAAShoXsAAAAAAAAFDSuIAFAAAAAACAksYFLAAAAAAAAJQ0LmABAAAAAACgpPV8P5nuvfdezZ07V83NzRo5cqTuuecejR49+pD52tvbtXHjRvXr10+ZTOb9FA0AAAAAAIAuIkkSbdu2TXV1dSorC//OKpMkSZLLhh977DFdffXVuv/++1VfX6+7775b8+fPV1NTkwYNGnTQvBs2bNCQIUNyKQ4AAAAAAABd3Pr163XccccFP8/5AlZ9fb3OOecc/fSnP5X03q+qhgwZohtuuEHf/va3D5p369at6t+/v16UdPQ/xE/8p3Tavy3w23jXxOrqTHCviR1jYqG+WWtim9KhjaZCdf/F5G03sZ2+6D2vpmPlsdf9bjOxnwfSfjUdevOadGzoZ9OxHf+WjvWdFijnNRM728TWmZjpc10QKOcH6dCCPenYP304HXvw/6RjX7osUM5qE7vGxJaYmLvG2xxZhtRxx9lvczr06v9Nx0Z8MR1L/tUX46Zm36EmODAd2rgsHasL/dbT/XCzwcROSIfe+Vg69kygmCvMmMusO26utj6ZjlWe4sv5men3628xCc0+/rv/nY5N+FE6tmO6L9vtPqe7su/1+Q/0S7fYSnrDxO6oNMEaE3vbxCYGKvCUiY00MfMfNO+avuwzNlBOdTr0+OPp2DyT9Rcmdoxb/8sDZbtj0tPp0DtmLKqvMHlHBcpZZWJ/M7EVJnZGOtT6v3wxla5OT5nqmHX55HPTsSUv+nI+er4JnmViLv8AEzNrliSpIh16x6zX1Z83ef8jHZpt1ocZW78VKNwsEtphYu5Asy8dejxwqneFOW979650bKbJ+89uh/yTL0cfMDF3YtPXxD5uYjf4YtZWpWMnmIPkvw9Ox9y+u8IXow+7yfXndOg/vpKOhdaDA434lI83P5eO1ZyZjiWvp2MZU+9/MTufJF33P03QnXDPMzEz2VeZekv+vKZmvAn+u4nNMbEVvhxtT4d+bFbxm39s8l5tquMWE0kfm2yC7gh9Uzr0/8wB8X6Tdc6vfNm/uiQde9mk++8npEILqtamYtf7UvSSif0PE5tpjnGzzbGnPlDO+Wa6vbgxHVtq8rpTa3M4kyQNN7HFJmZOF+yK98/uGCXpvz2bjn3QpFtpYu6rz+kmdkzg/PR8s0u60+2JZpf4FzOlXV9I0kRzrjXdnJy/Y/LeZ2Lm62bQF7+Ujt34YDrm+tfsOZKk681havP6dOwPJu/EyPvc/mYO2ZL0iom5frvKlDPdbDN0r9yFJna5id1pYm6feihQzq0m9l8P+HebpOWSWlpaVFVljuf/KadbCPfs2aNly5ZpxowZ2VhZWZnGjh2rxsbGVPrdu3dr9+7d2X9v27ZN0nvHqn7/kK6yV7qsthwqXOl+YeZiPSI3GMpv7nrc5urjtukuYLn6SDLn9iqPfVpZHxMLtfGodKhfOmTHx1W9rznZD5bv0ppybN7egXLM+JgmqtJU3nWba7ck33i3AZc/tt2BuWH7w6R154OV5qQ5dPXaFdM3cp+y+0TojmFXkBs00yB3jdpllfyY23kUGvOY7SkwjyLH3M5Vs8HQ1LBj7sqOvHvbtUXyU9iOr6uom0OhL3MurRsfk84l6xMa28ixsMceF3MJQ2uwq5PpSzfX7foUGjTXx7HrTuQ+IQXqZNpj56rpI3cpI5TWTszY9oT2CTO37Fi4/jVluyWn0u6kUvwB0VXeHQwDq32lqZUr2rXRLoQ5dKZtjyvc9pwvxp7EmLRucrlNuskqSZXuA7NyuGSxF7DsRJe/junGwg15xlQotG5Uuk6KbZCpe6gvY0887dxylQ91sInbqWWP5OlQcIGK7A+3AdcX9qAbKNwdvGz+9P7osob25uhqmg24Lg92pVk2XFq3TTcKoakeu83Y2RbadV0fuW26dLFLVuj8NPZ0u9IEXR2D59tm1409BXHtCY2ZLdsUFLs3BpdBMwfdf/Lbvow83w5d83DbdP+37MrJZf67/dl+z4/MG/qa7sY3dHp8qEdN5fQQ97ffflttbW0aPLjj/1wNHjxYzc3pa92zZ89WVVVV9g+3DwIAAAAAACBX7+sh7rFmzJih6dP/fr9La2tr97iI5X5tFbq8ergVqhy8P4xP6YjcT+2Qubz5lp1nOTap+zln5BzMqYlum7EbCNXHxfOpew77XmxSW04u638ebbRCfR5bTuQ4Bqvoys9jHgSzxpaTT7sPFn+f9fHt2RDY6F9MzNwC9a7Zyd3PxNyvdiRJW9Ihd4+C+2mtq7urjyT1cTf0OOa+dHefvL0vVoFHM5h7w7eaZK6Ntt2SH5+muPzuv7btXAs8S8CNT60ZC9fltWa8W3wx/lkaLrFLZ/rH1Vvy87XW9GXSmo5l3P7j6iPZ/ceOr+t3M4cCjwHx+7SbL+aGfDM8fnwC64ab17vi8rtfTYR+SRH7O0mXMPbXTqH8sWW7cnL4Ibb9BUv0D/cDBeVTjovZH1sFfoCYx00HNl0wr/nZkEsbOw9Cc8MumZE/soy9GSb0gUtrf5EW+oH1AXq7NVA5/FrRlFNhthnqy9h+j+230K/zMmYDfXd3/HfgbsqUnC5gDRw4UD169NDmzR1PJjZv3qyamvQDTyoqKlRRETl6AAAAAAAAgJHTLYTl5eUaNWqUFi1alI21t7dr0aJFGjNmzGGvHAAAAAAAAJDzLYTTp0/XlClTdPbZZ2v06NG6++67tWPHDl177bWdUT8AAAAAAAB0czlfwLryyiv117/+Vbfffruam5v1oQ99SE8//XTqwe4AAAAAAADA4fC+HuI+bdo0TZs27XDXBQAAAAAAAEjp1LcQhvRQ4M0JkXmjgoEn+ucl9olhOT1ZLA+unPfbsV3BkdB2V8dCzZfO6J8joc87QzH38VzEjo9Jl1PR+czrUB1dPLI9tugc5mps0ug+ymU/KdR+Wqh9tzP2lXznVmy6w9xHvtqh0zAXjzxly6nPzTZdfrtNkzfYZ7HtyScWYt6nlPf5nCvfvLQor2N+oI2xY2Ffq2UqlNOYuXdTRY5PqN2x7cm4hLnMjeC77iLSmVjecz1ym7H9E0wbmz/wBlGjYKd+3fUc04j+ypfD+l+oU9liOpLbeLjr3pV2pyN5XAEAAAAAANANcAELAAAAAAAAJY0LWAAAAAAAAChpXMACAAAAAABASSvKQ9zb/vPP+80bF+wE7Xmk64w6FqqcI8WR0HZXx9h51Rlll+I2jwSFGrMiyqmJ+cyDTphDtu45lBObtFOmQVfbTzujk2K3mW+7C9JvRwfifeOyu+dNu5fY2Ad6Bzbgtlnu8pq651KObbtrt3k4uvr7Ymz5Jm3kc7p9uyVfT1OOq4+L2TltticFnkVu+rL3W3GZg2Pmyq+KTOfqEyjGxt023VcWN4dC+1Tsg+4jxzb4E4DYOplt5rPvhdLaNqbz79JOE/Nc3KY1a+iO2LyBD9yu4vK7ckLv93Jx90h7V47dZqCgfMpJj47P2zfQmS682ydNcfUOvivNFOTSxs6h4NxwTIe4fnPtDrbHfODSunJiOzjURrdNN69j62jzBsqPnS/RfSEpMRs4sJx9gbwH4hdYAAAAAAAAKGlcwAIAAAAAAEBJ4wIWAAAAAAAAShoXsAAAAAAAAFDSivIQ96LpBg9eLpSCPRO4uz4kPE+d0m0ltv/k1EaX2D390rTRPtgxULgNu3JMwtgHgbrNBePuKYxuHE0sVI6tp9umSxibLhR3MfPfMHYcQvPXxGPfjxE93qH/Korso+j2hAYtl7QRhQeXArPNJPhk1ENvNLiPuw9i51suLz8xDz+2Sd1+Zvoitiu6pnxON13e7nX6ik7SIzZh159vbn0KLY3Rx8M8jq+hSsW+CymXB4/HbjP20BM6SOZT9+h3QOVQdj4vrMl3zGLHJzRm9rQq8hw+8rQ8+EHsVwqXMIn9nhEoxw5v5EPcQ+dusf3u2pjLmMXMdR7iDgAAAAAAgC6BC1gAAAAAAAAoaVzAAgAAAAAAQEnjAhYAAAAAAABKWk5PJbzjjjt05513doideuqpeuONNw5rpTpNoS7XFfOyYPQDKY+IYgpYUIEcyeNTYpe7c2qjS9zbxMxDm10yly5UjMrj8ttNmqDbnBSoZ9+4bdrtBZ7CGFtPG3NzyFY8v21G1zGH/G5s7SZde3IZNLPRHpEPr8+pL12dIhsZnEKm/EyFSbc7z3LcB66c2DkUWkxM3CY9ysRMX/j2HB0oPBQ/QMYMZLl5DGp56PGtpuMi56Wto6tPcKNVkelcLNA/tp4D49LFxoLl94/LH+qiFNc/Cuznpj5u/XeZQ+uGbaPpS5vOFB4qx8YHRCaMHAdJ0vZ0yI6vy29iOc0NNxhmm7HTPzT/3TpoF610/l56Ky5rIB57TuYOXcG8kecrbpu57M6u/Nh62m0Gzpdjy4k9TNlicii7U8Ys8riZ75hZkedzsac/oQ9cWrusm4QZE+sVON+OHnNXR3PID32Ni+33yK8zuZxup2KxXzVzfq3GmWeeqWeeeebvG+jZ9d/MAQAAAAAAgOLJ+epTz549VVNTE5V29+7d2r377//V2trammtxAAAAAAAA6OZyvilo5cqVqqur04knnqjJkydr3bp1wbSzZ89WVVVV9s+QIUPyqiwAAAAAAAC6n5wuYNXX12vevHl6+umndd9992nNmjU699xztW3bNpt+xowZ2rp1a/bP+vXrD0ulAQAAAAAA0H3kdAvhhAkTsn8fMWKE6uvrNXToUD3++OOaOnVqKn1FRYUqKtwTBQEAAAAAAIA4eT2BvX///jrllFO0atWqw1UfACiMyFey2DeT5PIKxMjXt8SWk9PPZmNe+RGQy9uH8nq9TS4F5fMmzFDePN6YE90XOZTt0nbKC0BjNxo7V0Mf5PFK1EKVk4vYNwDF99vbgZK2mph5i9q+PemYe6PRrkAx2hEV8vlb4uojST1N2tg3Ldq+CPSbreeGdGhnZN5gv7WYWHNc/sAbp9I2+7Cru+sPd3NEpZlDbrxD24xOtyWuPiG1ru2m7nYcQvU2+e34uvxmDgXH0dXJ9IebL24s7Pi4MuTnhq1nOn8uh67o46FJmNPyHbmOxr4dMJdDsZPXeUAgHBuLPg8IlJ3H6WBu9TEdn8+bFvN94/jhPpUMyeWNkAcKtTGf/SyXN0fGps0nnSRlzAcHviA5dmzyGsPt27dr9erVqq2tzWczAAAAAAAAQFBOF7BuueUWLV68WGvXrtVLL72kyy67TD169NCkSZM6q34AAAAAAADo5nK6hXDDhg2aNGmStmzZomOPPVYf//jHtWTJEh177LGdVT8AAAAAAAB0czldwPrlL3+ZV2FJkkhK34Xeau7Pbg1s410Ta203QRdrM7F9gYJc/iQdcrf0t7ptxtZHknuCxIH3iAa5Dgq10dwrb9tjxsfdkt+2O1COK9+ldffpu7yhZ1KY8XGPA2g1/W7nVej5Bm7c3AZc/th2B+aG7Q+T1j0potVMLNNlkny/tUXOYTuHQgW59rjCTYNcOfbRIPJjHvtsEjvXA+Nj51HkmNu5ajboypACY+7KDo1FRH0kP4Xt+Lo+cnMotG64tJHPjrG7Yyiv2S9c291UtccplzATKNvVyfSlK6eHyxuaHO6gErvuRO4TktTmyjHtsXPV9FuoHLs2u3kU2Z7gPmHmoB0L125TtltyWt3CLCl6sXfJcpkbbpFwi6urpjv5Cp1v9IxdJGJPGAIPVLKTy6R1k8sNbnASRj4ozCWLfaiLPXApcJCNnKyuQqFzqla3EroGRS4mbmwkvz7atrs5lMtDxkzc7pQuGDmHpMACFXni6PrI7nuBI7TbzyMP2m6LoaXRTUFbjJmWrneDXWnyxz6iz9Unl/Mnt83o7g1MQZfW9btLF7tk9QgsG7Gn225quXYHz7dN22NPQVx7QmNmyzYFubJdXwQPkWYOxn7/CH73OTBdIO7GPLYc1+7gmJmY6yNXH9cXwUOKqeeB5ez/9/5rRiGZ5FApDqMNGzZoyJAhhSoOAAAAAAAAR4D169fruOOOC35e0AtY7e3t2rhxo/r166dt27ZpyJAhWr9+vSorKwtVBZSY1tZW5gGYB2AOQBLzAO9hHkBiHoA5gPcwD7qHJEm0bds21dXVqaws/Kj2nG4hzFdZWVn2alom895vhisrK5mIYB5AEvMAzAG8h3kAiXmA9zAPwByAxDzoDqqqqg6ZJqe3EAIAAAAAAACFxgUsAAAAAAAAlLSiXcCqqKjQrFmzVFFRUawqoAQwDyAxD8AcwHuYB5CYB3gP8wDMAUjMA3RU0Ie4AwAAAAAAALniFkIAAAAAAACUNC5gAQAAAAAAoKRxAQsAAAAAAAAljQtYAAAAAAAAKGlcwAIAAAAAAEBJK9oFrHvvvVcnnHCCevfurfr6er388svFqgo62ezZs3XOOeeoX79+GjRokC699FI1NTV1SPPJT35SmUymw5+vfvWrRaoxOsMdd9yRGuPTTjst+/muXbvU0NCgAQMG6Oijj9bEiRO1efPmItYYneGEE05IzYNMJqOGhgZJrAVd0QsvvKCLL75YdXV1ymQyeuqppzp8niSJbr/9dtXW1qpPnz4aO3asVq5c2SHNO++8o8mTJ6uyslL9+/fX1KlTtX379gK2Avk62DzYu3evbrvtNg0fPlx9+/ZVXV2drr76am3cuLHDNtz6cddddxW4JcjHodaDa665JjXG48eP75CG9eDId6h54M4TMpmM5s6dm03DenBki/l+GPPdYN26dbrooot01FFHadCgQbr11lu1b9++QjYFBVaUC1iPPfaYpk+frlmzZmn58uUaOXKkxo0bp7feeqsY1UEnW7x4sRoaGrRkyRItXLhQe/fu1YUXXqgdO3Z0SHfddddp06ZN2T9z5swpUo3RWc4888wOY/yHP/wh+9nNN9+sX//615o/f74WL16sjRs36vLLLy9ibdEZXnnllQ5zYOHChZKkz33uc9k0rAVdy44dOzRy5Ejde++99vM5c+boJz/5ie6//34tXbpUffv21bhx47Rr165smsmTJ+v111/XwoULtWDBAr3wwgv6yle+Uqgm4DA42DzYuXOnli9frpkzZ2r58uV64okn1NTUpM985jOptN/73vc6rA833HBDIaqPw+RQ64EkjR8/vsMYP/roox0+Zz048h1qHvzj+G/atEkPPvigMpmMJk6c2CEd68GRK+b74aG+G7S1temiiy7Snj179NJLL+nhhx/WvHnzdPvttxejSSiUpAhGjx6dNDQ0ZP/d1taW1NXVJbNnzy5GdVBgb731ViIpWbx4cTb2iU98IrnxxhuLVyl0ulmzZiUjR460n7W0tCS9evVK5s+fn439+c9/TiQljY2NBaohiuHGG29MTjrppKS9vT1JEtaCrk5S8uSTT2b/3d7entTU1CRz587NxlpaWpKKiork0UcfTZIkSf70pz8lkpJXXnklm+Z3v/tdkslkkr/85S8FqzsOnwPngfPyyy8nkpI333wzGxs6dGjy4x//uHMrh4Jx82DKlCnJJZdcEszDetD1xKwHl1xySXL++ed3iLEedC0Hfj+M+W7w29/+NikrK0uam5uzae67776ksrIy2b17d2EbgIIp+C+w9uzZo2XLlmns2LHZWFlZmcaOHavGxsZCVwdFsHXrVklSdXV1h/gvfvELDRw4UGeddZZmzJihnTt3FqN66EQrV65UXV2dTjzxRE2ePFnr1q2TJC1btkx79+7tsC6cdtppOv7441kXurA9e/bo5z//ub70pS8pk8lk46wF3ceaNWvU3NzcYd+vqqpSfX19dt9vbGxU//79dfbZZ2fTjB07VmVlZVq6dGnB64zC2Lp1qzKZjPr3798hftddd2nAgAH68Ic/rLlz53KrSBf0/PPPa9CgQTr11FP1ta99TVu2bMl+xnrQ/WzevFm/+c1vNHXq1NRnrAddx4HfD2O+GzQ2Nmr48OEaPHhwNs24cePU2tqq119/vYC1RyH1LHSBb7/9ttra2jpMNEkaPHiw3njjjUJXBwXW3t6um266SR/72Md01llnZeOf//znNXToUNXV1enVV1/VbbfdpqamJj3xxBNFrC0Op/r6es2bN0+nnnqqNm3apDvvvFPnnnuuXnvtNTU3N6u8vDz1RWXw4MFqbm4uToXR6Z566im1tLTommuuycZYC7qX/fu3OyfY/1lzc7MGDRrU4fOePXuqurqa9aGL2rVrl2677TZNmjRJlZWV2fg3vvENfeQjH1F1dbVeeuklzZgxQ5s2bdKPfvSjItYWh9P48eN1+eWXa9iwYVq9erW+853vaMKECWpsbFSPHj1YD7qhhx9+WP369Us9VoL1oOtw3w9jvhs0Nzfb84f9n6FrKvgFLHRvDQ0Neu211zo8+0hSh2cXDB8+XLW1tbrgggu0evVqnXTSSYWuJjrBhAkTsn8fMWKE6uvrNXToUD3++OPq06dPEWuGYnnggQc0YcIE1dXVZWOsBUD3tnfvXl1xxRVKkkT33Xdfh8+mT5+e/fuIESNUXl6u66+/XrNnz1ZFRUWhq4pOcNVVV2X/Pnz4cI0YMUInnXSSnn/+eV1wwQVFrBmK5cEHH9TkyZPVu3fvDnHWg64j9P0QcAp+C+HAgQPVo0eP1BsENm/erJqamkJXBwU0bdo0LViwQM8995yOO+64g6atr6+XJK1ataoQVUMR9O/fX6eccopWrVqlmpoa7dmzRy0tLR3SsC50XW+++aaeeeYZffnLXz5oOtaCrm3//n2wc4KamprUS1727dund955h/Whi9l/8erNN9/UwoULO/z6yqmvr9e+ffu0du3awlQQBXfiiSdq4MCB2WMA60H38uKLL6qpqemQ5woS68GRKvT9MOa7QU1NjT1/2P8ZuqaCX8AqLy/XqFGjtGjRomysvb1dixYt0pgxYwpdHRRAkiSaNm2annzyST377LMaNmzYIfOsWLFCklRbW9vJtUOxbN++XatXr1Ztba1GjRqlXr16dVgXmpqatG7dOtaFLuqhhx7SoEGDdNFFFx00HWtB1zZs2DDV1NR02PdbW1u1dOnS7L4/ZswYtbS0aNmyZdk0zz77rNrb27MXOHHk23/xauXKlXrmmWc0YMCAQ+ZZsWKFysrKUreUoevYsGGDtmzZkj0GsB50Lw888IBGjRqlkSNHHjIt68GR5VDfD2O+G4wZM0Z//OMfO1zU3v+fH2eccUZhGoKCK8othNOnT9eUKVN09tlna/To0br77ru1Y8cOXXvttcWoDjpZQ0ODHnnkEf3qV79Sv379svckV1VVqU+fPlq9erUeeeQRffrTn9aAAQP06quv6uabb9Z5552nESNGFLn2OFxuueUWXXzxxRo6dKg2btyoWbNmqUePHpo0aZKqqqo0depUTZ8+XdXV1aqsrNQNN9ygMWPG6KMf/Wixq47DrL29XQ899JCmTJminj3/fhhiLeiatm/f3uEXdGvWrNGKFStUXV2t448/XjfddJO+//3v64Mf/KCGDRummTNnqq6uTpdeeqkk6fTTT9f48eN13XXX6f7779fevXs1bdo0XXXVVR1uP0VpO9g8qK2t1Wc/+1ktX75cCxYsUFtbW/Zcobq6WuXl5WpsbNTSpUv1qU99Sv369VNjY6NuvvlmfeELX9AxxxxTrGYhRwebB9XV1brzzjs1ceJE1dTUaPXq1frWt76lk08+WePGjZPEetBVHOq4IL33nxnz58/XD3/4w1R+1oMj36G+H8Z8N7jwwgt1xhln6Itf/KLmzJmj5uZmffe731VDQwO3kXZlxXr94T333JMcf/zxSXl5eTJ69OhkyZIlxaoKOpkk++ehhx5KkiRJ1q1bl5x33nlJdXV1UlFRkZx88snJrbfemmzdurW4FcdhdeWVVya1tbVJeXl58oEPfCC58sork1WrVmU/f/fdd5Ovf/3ryTHHHJMcddRRyWWXXZZs2rSpiDVGZ/n973+fSEqampo6xFkLuqbnnnvOHgOmTJmSJEmStLe3JzNnzkwGDx6cVFRUJBdccEFqbmzZsiWZNGlScvTRRyeVlZXJtddem2zbtq0IrcH7dbB5sGbNmuC5wnPPPZckSZIsW7Ysqa+vT6qqqpLevXsnp59+evKDH/wg2bVrV3EbhpwcbB7s3LkzufDCC5Njjz026dWrVzJ06NDkuuuuS5qbmztsg/XgyHeo40KSJMnPfvazpE+fPklLS0sqP+vBke9Q3w+TJO67wdq1a5MJEyYkffr0SQYOHJh885vfTPbu3Vvg1qCQMkmSJJ14fQwAAAAAAADIS8GfgQUAAAAAAADkggtYAAAAAAAAKGlcwAIAAAAAAEBJ4wIWAAAAAAAAShoXsAAAAAAAAFDSuIAFAAAAAACAksYFLAAAAAAAAJQ0LmABAAAAAACgpHEBCwAAAAAAACWNC1gAAAAAAAAoaVzAAgAAAAAAQEn7/1plnEaElD8aAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(final_attention, cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
